{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drive2gcp",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmt19/siim_otani/blob/master/drive2gcp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_b3xu4SYbCZ",
        "colab_type": "code",
        "outputId": "93c84f56-aee4-4877-fc62-c5b6e39106f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from google import colab\n",
        "colab.drive.mount('/content/gdrive')\n",
        "!ls 'gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "'Colab Notebooks'    dicom-images-train   手法のアイデア.gdoc\n",
            " dicom-images-test   train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaQ7Rl4XYwrd",
        "colab_type": "code",
        "outputId": "fe13ed3a-af71-4f07-c4c3-aade46c813ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install pydicom\n",
        "!git clone https://github.com/kmt19/siim_otani/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/88/d3c419ab2e753e7651510882a53219373e78fb55294cb247dffd3934ea55/pydicom-1.2.2-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-1.2.2\n",
            "Cloning into 'siim_otani'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 44 (delta 19), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n",
            "gdrive\tsample_data  siim_otani\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sra6vodkVJyc",
        "colab_type": "code",
        "outputId": "799bf6e1-5a40-4874-bade-89f81f168b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import pydicom\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from siim_otani.mask_functions import mask2rle,rle2mask\n",
        "from siim_otani.pipline2 import get_dataloaders\n",
        "DRIVE_DIR = 'gdrive/My Drive/'\n",
        "folders = os.listdir(DRIVE_DIR)\n",
        "print(folders)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['手法のアイデア.gdoc', 'dicom-images-test', 'dicom-images-train', 'Colab Notebooks', 'train.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP-mVYC_TTOA",
        "colab_type": "code",
        "outputId": "093085a3-d410-4839-f8bc-925735ff7510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_dicom_dir = os.path.join(DRIVE_DIR, 'dicom-images-train')\n",
        "test_dicom_dir = os.path.join(DRIVE_DIR, 'dicom-images-test')\n",
        "print(os.listdir(train_dicom_dir)[0])\n",
        "a_dir = os.path.join(train_dicom_dir, os.listdir(train_dicom_dir)[0])\n",
        "print(os.listdir(a_dir))\n",
        "b_dir = os.path.join(a_dir, os.listdir(a_dir)[0])\n",
        "print(os.listdir(b_dir))\n",
        "\"\"\"\n",
        "ここから各Directory内のlistを読み込み、\n",
        "BASE_DIR = 'train_dicom_dir/%s/%s/' % (file_list, file_list2)を\n",
        "for文でもらってきて最終的にpathを保存したdataframeを作成する。\n",
        "\"\"\"\n",
        "for filename in os.listdir(train_dicom_dir):\n",
        "  BASE_DIR = 'train_dicom_dir/%s/%s/' % (filename, filename)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2.276.0.7230010.3.1.2.8323329.13318.1517875244.629616\n",
            "['1.2.276.0.7230010.3.1.3.8323329.13318.1517875244.629615']\n",
            "['1.2.276.0.7230010.3.1.4.8323329.13318.1517875244.629617.dcm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIRpfypbvmx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets.folder import pil_loader\n",
        "import pydicom\n",
        "from PIL import Image\n",
        "from __future__ import print_function\n",
        "from collections import defaultdict, deque\n",
        "import datetime\n",
        "import pickle\n",
        "import time\n",
        "import torch.distributed as dist\n",
        "import errno\n",
        "import collections\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7rczN80szHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dicom_dir = os.path.join(DRIVE_DIR, 'dicom-images-train')\n",
        "test_dicom_dir = os.path.join(DRIVE_DIR, 'dicom-images-test')\n",
        "data_files={}\n",
        "phase = [\"train\",\"test\"]\n",
        "data_files[\"train\"] = pd.DataFrame(columns=['Path', 'ID'])\n",
        "data_files[\"test\"] = pd.DataFrame(columns=['Path'])\n",
        "SEGMENTATION = DRIVE_DIR + 'train.csv'\n",
        "anns = pd.read_csv(SEGMENTATION)\n",
        "train_list=os.listdir(train_dicom_dir)\n",
        "\n",
        "for i, filename in tqdm(enumerate(train_list)):\n",
        "  train_glob = f'{train_dicom_dir}/{filename}/*/*.dcm'\n",
        "  data_files[\"train\"].loc[i] = [glob(train_glob)[0], anns.loc[i][1]]\n",
        "  if i==10:\n",
        "    break\n",
        "\n",
        "test_list=os.listdir(test_dicom_dir)  \n",
        "for i, filename in tqdm(enumerate(test_list)):\n",
        "  test_glob = f'{test_dicom_dir}/{filename}/*/*.dcm'\n",
        "  data_files[\"test\"].loc[i] = [glob(test_glob)[0]]\n",
        "  if i==10:\n",
        "    break\n",
        "traindataloader = get_dataloaders(data_files)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQILfRYutY0Y",
        "colab_type": "code",
        "outputId": "06849d8c-9ec6-40fa-fc97-4a31d5022d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor folder in folders:\\n  new_folder = path + '/' + folder\\n  new_folder = new_folder + '/' + os.listdir(new_folder)[0]\\n  new_file = new_folder + '/' + os.listdir(new_folder)[0]\\n  ds = pydicom.dcmread(new_file)\\n  break\\n  \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV0QWlbJN0al",
        "colab_type": "code",
        "outputId": "bb66235e-7d0f-4dbf-90d4-c3a30a398240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def reduce_dict(input_dict, average=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dict (dict): all the values will be reduced\n",
        "        average (bool): whether to do average or sum\n",
        "    Reduce the values in the dictionary from all processes so that all processes\n",
        "    have the averaged results. Returns a dict with the same fields as\n",
        "    input_dict, after reduction.\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size < 2:\n",
        "        return input_dict\n",
        "    with torch.no_grad():\n",
        "        names = []\n",
        "        values = []\n",
        "        # sort the keys so that they are consistent across processes\n",
        "        for k in sorted(input_dict.keys()):\n",
        "            names.append(k)\n",
        "            values.append(input_dict[k])\n",
        "        values = torch.stack(values, dim=0)\n",
        "        dist.all_reduce(values)\n",
        "        if average:\n",
        "            values /= world_size\n",
        "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
        "    return reduced_dict\n",
        "  \n",
        "  def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
        "\n",
        "    def f(x):\n",
        "        if x >= warmup_iters:\n",
        "            return 1\n",
        "        alpha = float(x) / warmup_iters\n",
        "        return warmup_factor * (1 - alpha) + alpha\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
        "    model.train()\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1. / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "\n",
        "        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
        "\n",
        "    for images, targets in data_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # reduce losses over all GPUs for logging purposes\n",
        "        loss_dict_reduced = reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY5F-ZohkKUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mask rcnn model\n",
        "num_classes = 2\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "model_ft = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features = model_ft.roi_heads.box_predictor.cls_score.in_features\n",
        "model_ft.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "in_features_mask = model_ft.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "hidden_layer = 256\n",
        "model_ft.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "model_ft.to(device)\n",
        "\n",
        "for param in model_ft.parameters():\n",
        "    param.requires_grad = True\n",
        "params = [p for p in model_ft.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.1)\n",
        "\n",
        "num_epochs = 6\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model_ft, optimizer, traindataloader[\"train\"], device, epoch, print_freq=100)\n",
        "    lr_scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}